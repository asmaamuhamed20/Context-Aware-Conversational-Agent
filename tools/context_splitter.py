from langchain.tools import Tool
from langchain_core.prompts import PromptTemplate
from langchain_core.language_models import BaseLanguageModel
from langchain_core.output_parsers import StrOutputParser


def build_context_splitter_tool(llm: BaseLanguageModel) -> Tool:
    with open('prompts/context_judge_prompt.txt', 'r') as f:
        prompt_template = f.read();

    prompt = PromptTemplate.from_template(prompt_template)

    chain = prompt | llm | StrOutputParser()

    tool = Tool.from_function(
        func=lambda input_str: chain.invoke({"input": input_str}),
        name = "ContextSplitter",
        description="Use this tool after 'ContextRelevanceChecker' confirms the context is relevant. It separates the background context from the user's actual question. Input is the user's full message. The output will contain the separated context and question."
    )
    return tool